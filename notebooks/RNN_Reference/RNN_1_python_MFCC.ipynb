{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "# Math\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "uav_path = '../data/phantom/JUNE_01_PHANTOMS/wavs/22050/*.*'\n",
    "none_path = '../data/phantom/JUNE_02_BACKGROUND/wavs/background/22050/background_*.*'\n",
    "uav_files = glob.glob(uav_path)\n",
    "none_files = glob.glob(none_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 개\t ../data/phantom/JUNE_01_PHANTOMS/wavs/22050\\LGgram_P2_loaded bck and forth.wav\n",
      "25 개\t ../data/phantom/JUNE_02_BACKGROUND/wavs/background/22050\\background_06_02_01.WAV\n"
     ]
    }
   ],
   "source": [
    "print(len(uav_files),'개\\t', uav_files[0])\n",
    "print(len(none_files), '개\\t',none_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "The reason of why SR is 44100 is that the sample rate of above files is 44.1kbps\n",
    "\n",
    "a wav file sample has 884736. if sample is divided by sample rate, the value is time\n",
    "the time is fixed by 20.06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(files, sr=44100):\n",
    "    [raw, sr] = librosa.load(files[0], sr=sr)\n",
    "    for f in files[1:]:\n",
    "        [array, sr] = librosa.load(f, sr=sr)\n",
    "        raw = np.hstack((raw, array))\n",
    "    print(raw.shape)\n",
    "    return raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75718272,)\n",
      "(21921792,)\n"
     ]
    }
   ],
   "source": [
    "SR = 22050\n",
    "uav_raw = load(uav_files)\n",
    "none_raw = load(none_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature extraction \n",
    "## steps\n",
    "#### 1. Resampling \n",
    "#### 2. *VAD*( Voice Activity Detection)\n",
    "#### 3. Maybe padding with 0 to make signals be equal length\n",
    "#### 4. Log spectrogram (or *MFCC*, or *PLP*)\n",
    "#### 5. Features normalization with *mean* and *std*\n",
    "#### 6. Stacking of a given number of frames to get temporal information\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Resampling\n",
    "\n",
    "if you see the graph, there are few at high frequency. this is mean that data is big but it's no useless. so To small the data, do Resampling. In general, use 0~8000Hz "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showFreqTime(combine):\n",
    "    for sample, filename, _ in combine:\n",
    "        freqs, times, spectrogram = log_specgram(sample, SR)\n",
    "        fig = plt.figure(figsize=(14, 10))\n",
    "        ax1 = fig.add_subplot(211)\n",
    "        ax1.set_title('Raw wave of ' + filename)\n",
    "        ax1.set_ylabel('Amplitude')\n",
    "        ax1.plot(np.linspace(0, len(sample)/SR, len(sample)), sample)\n",
    "\n",
    "        ax2 = fig.add_subplot(212)\n",
    "        ax2.imshow(spectrogram.T, aspect='auto', origin='lower', \n",
    "               extent=[times.min(), times.max(), freqs.min(), freqs.max()])\n",
    "        ax2.set_yticks(freqs[::16])\n",
    "        ax2.set_xticks(times[::16])\n",
    "        ax2.set_title('Spectrogram of ' + filename)\n",
    "        ax2.set_ylabel('Freqs in Hz')\n",
    "        ax2.set_xlabel('Seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#showFreqTime(combine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_fft(y, fs):\n",
    "    T = 1.0 / fs\n",
    "    N = y.shape[0]\n",
    "    yf = fft(y)\n",
    "    xf = np.linspace(0.0, 1.0/(2.0*T), N//2)\n",
    "    vals = 2.0/N * np.abs(yf[0:N//2])  # FFT is simmetrical, so we take just the first half\n",
    "    # FFT is also complex, to we take just the real part (abs)\n",
    "    return xf, vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data diffrence\n",
    "\n",
    "qualiy is diffrence but, the data is almost same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ipd.Audio(combine_prev[0][0], rate=combine_prev[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ipd.Audio(combine[0][0], rate=combine[0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. VAD\n",
    "\n",
    "Sometimes, Files have silence. It is not necessary. So, We need to find sound of Drone except silence.\n",
    "\n",
    "But, Not yet implemented"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. padding with 0 to make signals be equal length\n",
    "\n",
    "If we have a lot of sound files, we need to pad some datas. But These files's time is longger than 1 second. So It dosn't need to pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Log spectrogram (or MFCC, or PLP)\n",
    "\n",
    "The upper picture is resampled data. \n",
    "The lower picture is original data.\n",
    "\n",
    "In MFCC Feature, There is no big difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "#returns mfcc features with mean and standard deviation along time\n",
    "def mfcc4(raw, label, chunk_size=8192, window_size=4096, sr=22050, n_mfcc=16, n_frame=16):\n",
    "    mfcc = np.empty((0, n_mfcc* n_frame))\n",
    "    y = []\n",
    "    print(raw.shape)\n",
    "    for i in range(0, len(raw), chunk_size//2):\n",
    "        mfcc_slice = librosa.feature.mfcc(raw[i:i+chunk_size], sr=sr, n_mfcc=n_mfcc) #n_mfcc,17\n",
    "        if mfcc_slice.shape[1] < 17:\n",
    "            print(\"small end:\", mfcc_slice.shape)\n",
    "            continue\n",
    "        mfcc_slice = mfcc_slice[:,:-1]\n",
    "        #print(mfcc_slice.shape)\n",
    "        mfcc_slice = mfcc_slice.reshape((1, mfcc_slice.shape[0]* mfcc_slice.shape[1]))\n",
    "        #print(mfcc_slice.shape)\n",
    "        mfcc = np.vstack((mfcc, mfcc_slice))\n",
    "        y.append(label)\n",
    "    y = np.array(y)\n",
    "    return mfcc, y\n",
    "\n",
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75718272,)\n",
      "small end: (16, 16)\n",
      "small end: (16, 8)\n",
      "(18484, 256) (18484,)\n",
      "(21921792,)\n",
      "small end: (16, 9)\n",
      "(5351, 256) (5351,)\n"
     ]
    }
   ],
   "source": [
    "mfcc_uav, y_uav = mfcc4(uav_raw, 1)\n",
    "print(mfcc_uav.shape, y_uav.shape)\n",
    "mfcc_none, y_none = mfcc4(none_raw, 0)\n",
    "print(mfcc_none.shape, y_none.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18484, 256) (18484,)\n",
      "(5351, 256) (5351,)\n"
     ]
    }
   ],
   "source": [
    "print(mfcc_uav.shape, y_uav.shape)\n",
    "print(mfcc_none.shape, y_none.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Features normalization with *mean* and *std*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Stacking of a given number of frames to get temporal information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23835, 256) (23835,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23835, 256)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate((mfcc_uav, mfcc_none), axis=0)\n",
    "y = np.hstack((y_uav, y_none))\n",
    "print(X.shape, y.shape)\n",
    "X = np.reshape(X,(X.shape[0],-1))# 선범 \n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23835,)\n",
      "(23835,)\n"
     ]
    }
   ],
   "source": [
    "# or should we give one label to one chunk?\n",
    "y_uav = np.ones(shape = [len(X)], dtype=int)\n",
    "y_none =np.zeros(shape =[len(y)], dtype=int)\n",
    "\n",
    "print(y_uav.shape)\n",
    "print(y_none.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataX = X\n",
    "dataY = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23835, 256) (23835,)\n"
     ]
    }
   ],
   "source": [
    "print(dataX.shape, dataY.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23827, 9, 256) (23827, 1)\n"
     ]
    }
   ],
   "source": [
    "seq_length = 9 #layer\n",
    "X_hot_list= []\n",
    "#Y_hot = dataY[seq_length-1:].reshape(len(dataY[seq_length-1:]), 1)\n",
    "Y_hot_tmp = dataY[seq_length-1:]\n",
    "\n",
    "for i in range(0, dataX.shape[0] - seq_length+1):\n",
    "    _x = dataX[i:i + seq_length]\n",
    "    #if i<10:\n",
    "        #print(_x, \"->\", Y_hot_tmp[i])\n",
    "    X_hot_list.append(_x)\n",
    "\n",
    "X_hot = np.array(X_hot_list[:])\n",
    "Y_hot = Y_hot_tmp.reshape((len(Y_hot_tmp),1))\n",
    "print(X_hot.shape, Y_hot.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uav_len, none_len -8 23835\n",
      "train_uav, test_uav -7 -1\n",
      "(23820, 9, 256) (0, 9, 256)\n",
      "(23820, 1) (0, 1)\n",
      "none 21451 2384\n",
      "(0, 9, 256) (2384, 9, 256)\n",
      "(0, 1) (2384, 1)\n",
      "23827\n"
     ]
    }
   ],
   "source": [
    "X_dim = 256\n",
    "X_train = np.zeros(shape=[0,9,X_dim],dtype=float)\n",
    "y_train = np.zeros(shape=[0,1],dtype=float)\n",
    "X_test = np.zeros(shape=[0,9,X_dim],dtype=float)\n",
    "y_test = np.zeros(shape=[0,1],dtype=float)\n",
    "\n",
    "split_rate = 0.9\n",
    "none_len = len(y_none)\n",
    "uav_len = len(X_hot) - none_len\n",
    "print('uav_len, none_len', uav_len,none_len)\n",
    "\n",
    "train_size = int(uav_len * split_rate)\n",
    "test_size = uav_len - train_size\n",
    "base = 0\n",
    "print('train_uav, test_uav',train_size,test_size)\n",
    "\n",
    "X_tr, X_te = np.array(X_hot[base:base+train_size]),np.array(X_hot[base+train_size:base+train_size+test_size])\n",
    "y_tr, y_te = np.array(Y_hot[base:base+train_size]),np.array(Y_hot[base+train_size:base+train_size+test_size])\n",
    "print(X_tr.shape,X_te.shape)\n",
    "print(y_tr.shape,y_te.shape)\n",
    "\n",
    "X_train = np.vstack((X_train,X_tr))\n",
    "X_test= np.vstack((X_test,X_te))\n",
    "y_train= np.vstack((y_train,y_tr))\n",
    "y_test= np.vstack((y_test,y_te))\n",
    "\n",
    "train_size = int(none_len * split_rate)\n",
    "test_size = none_len - train_size\n",
    "base = uav_len\n",
    "print('none',train_size,test_size)\n",
    "\n",
    "X_tr, X_te = np.array(X_hot[base:base+train_size]),np.array(X_hot[base+train_size:base+train_size+none_len])\n",
    "y_tr, y_te = np.array(Y_hot[base:base+train_size]),np.array(Y_hot[base+train_size:base+train_size+none_len])\n",
    "print(X_tr.shape,X_te.shape)\n",
    "print(y_tr.shape,y_te.shape)\n",
    "\n",
    "print(base+none_len)\n",
    "X_train = np.vstack((X_train,X_tr))\n",
    "X_test= np.vstack((X_test,X_te))\n",
    "y_train= np.vstack((y_train,y_tr))\n",
    "y_test= np.vstack((y_test,y_te))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23820, 9, 256) (2384, 9, 256)\n",
      "(23820, 1) (2384, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nnp.save('../data/Xy/X_train2', X_train)\\nnp.save('../data/Xy/X_test2', X_test)\\nnp.save('../data/Xy/y_train2', y_train)\\nnp.save('../data/Xy/y_test2', y_test)\\n\""
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "np.save('../data/Xy/X_train2', X_train)\n",
    "np.save('../data/Xy/X_test2', X_test)\n",
    "np.save('../data/Xy/y_train2', y_train)\n",
    "np.save('../data/Xy/y_test2', y_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nX_train = np.load('../data/Xy/X_train2.npy')\\nX_test = np.load('../data/Xy/X_test2.npy')\\ny_train = np.load('../data/Xy/y_train2.npy')\\ny_test = np.load('../data/Xy/y_test2.npy')\\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "X_train = np.load('../data/Xy/X_train2.npy')\n",
    "X_test = np.load('../data/Xy/X_test2.npy')\n",
    "y_train = np.load('../data/Xy/y_train2.npy')\n",
    "y_test = np.load('../data/Xy/y_test2.npy')\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "\n",
    "# train Parameters\n",
    "#X_dim = 442 #n_dim #X_hot.shape[2]\n",
    "\n",
    "#seq_length = #X_hot.shape[1]\n",
    "output_dim = 1 #n_classes #Y_hot.shape[1]\n",
    "\n",
    "hidden_dim = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, seq_length, X_dim], name = 'X')\n",
    "Y = tf.placeholder(tf.float32, [None, output_dim], name = 'Y')\n",
    "\n",
    "#X_one_hot = tf.one_hot(X, )\n",
    "# build a LSTM network\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units=hidden_dim, state_is_tuple=True, activation=tf.tanh)\n",
    "#cell = tf.contrib.rnn.MultiRNNCell([cell]*2, state_is_tuple=True)\n",
    "outputs, _states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "\n",
    "Y_pred = tf.contrib.layers.fully_connected(\n",
    "    outputs[:, -1], output_dim, activation_fn=None)  # We use the last cell's output\n",
    "\n",
    "# cost/loss\n",
    "loss = tf.reduce_sum(tf.square(Y_pred - Y))  # sum of the squares\n",
    "#loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Y_pred, labels = Y))\n",
    "\n",
    "# optimizer\n",
    "lr = tf.placeholder(tf.float32,shape=(), name='learning_rate')\n",
    "train = tf.train.AdamOptimizer(lr).minimize(loss) #AdamOptimizer\n",
    "\n",
    "# RMSE\n",
    "targets = tf.placeholder(tf.float32, [None, output_dim] , name = 'targets')\n",
    "predictions = tf.placeholder(tf.float32, [None, output_dim] , name = 'predictions')\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square(targets - predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-217.22691805, -225.90947428, -259.03216283, ...,   -6.84148284,\n",
       "          -9.83497063,   -5.24579655],\n",
       "       [-204.09500396, -216.19582211, -246.3247065 , ...,   -5.0652497 ,\n",
       "          -2.52530122,   -2.09315019],\n",
       "       [-223.15359868, -231.14346908, -256.00372179, ...,    2.70678687,\n",
       "          -0.94429221,   -5.53733516],\n",
       "       ...,\n",
       "       [-247.48963791, -247.07030972, -248.1789639 , ...,   -4.28789018,\n",
       "          -1.23542643,   -0.38626453],\n",
       "       [-197.79129797, -211.73574008, -244.0251253 , ...,   -1.52421738,\n",
       "          -1.52261091,    1.54296295],\n",
       "       [-232.30992305, -232.90745687, -232.78914617, ...,   -6.58980176,\n",
       "         -11.48347484,   -8.32239321]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[step: 0] loss: 2.132034037835852\n",
      "[step: 1] loss: 0.7450620867443325\n",
      "[step: 2] loss: 0.7165224371589001\n",
      "[step: 3] loss: 0.6891175187604954\n",
      "[step: 4] loss: 0.6624723676269941\n",
      "[step: 5] loss: 0.6366240865737826\n",
      "[step: 6] loss: 0.611533399913413\n",
      "[step: 7] loss: 0.5872174446368598\n",
      "[step: 8] loss: 0.5636617075986566\n",
      "[step: 9] loss: 0.5408871385652813\n",
      "Test accuracy: 1.040\n",
      "[step: 0] loss: 0.5189082096846138\n",
      "[step: 1] loss: 0.5029531381192276\n",
      "[step: 2] loss: 0.4874519098315491\n",
      "[step: 3] loss: 0.4724406846924853\n",
      "[step: 4] loss: 0.4578638289777498\n",
      "[step: 5] loss: 0.44375397676584805\n",
      "[step: 6] loss: 0.4300951799958018\n",
      "[step: 7] loss: 0.41689772906171285\n",
      "[step: 8] loss: 0.40414547091467257\n",
      "[step: 9] loss: 0.39185472259393367\n",
      "Test accuracy: 0.805\n",
      "[step: 0] loss: 0.3799814526920655\n",
      "[step: 1] loss: 0.3723411835511125\n",
      "[step: 2] loss: 0.36489807180153233\n",
      "[step: 3] loss: 0.35766605662258605\n",
      "[step: 4] loss: 0.3506384554077456\n",
      "[step: 5] loss: 0.34381824048200044\n",
      "[step: 6] loss: 0.33719592090417716\n",
      "[step: 7] loss: 0.3307508338909005\n",
      "[step: 8] loss: 0.32449982945004197\n",
      "[step: 9] loss: 0.3184180015480689\n",
      "Test accuracy: 0.756\n",
      "[step: 0] loss: 0.3125587905384131\n",
      "[step: 1] loss: 0.30967479484807936\n",
      "[step: 2] loss: 0.3068798254158795\n",
      "[step: 3] loss: 0.30412126184010285\n",
      "[step: 4] loss: 0.30142265723394207\n",
      "[step: 5] loss: 0.29875974102644837\n",
      "[step: 6] loss: 0.29615778822942906\n",
      "[step: 7] loss: 0.2935887974916037\n",
      "[step: 8] loss: 0.29107236565911\n",
      "[step: 9] loss: 0.28859445105872167\n",
      "Test accuracy: 0.742\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "cost_history = np.empty(shape=[1],dtype=float)\n",
    "step_loss = 999999.0\n",
    "model_path = '../models/RNN/my_RNN_model_S9_40'\n",
    "saver = tf.train.Saver()\n",
    "training_epochs = 10\n",
    "# Training step\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init)\n",
    "for learning_rate in [0.02, 0.015, 0.01, 0.005]:\n",
    "    test_acc = []\n",
    "    feed = {lr:learning_rate, X: X_train, Y: y_train}\n",
    "    for i in range(training_epochs):\n",
    "        step_loss_prev = step_loss\n",
    "        _, step_loss = sess.run([train, loss], feed_dict=feed)\n",
    "        cost_history = np.append(cost_history,step_loss/X_train.shape[0])\n",
    "        \n",
    "        print(\"[step: {}] loss: {}\".format(i, step_loss/X_train.shape[0]))\n",
    "        #batch_acc, test_state = sess.run([loss, _states], feed_dict=feed)\n",
    "    print(\"Test accuracy: {:.3f}\".format(1.0-np.mean(cost_history)))\n",
    "\n",
    "saver.save(sess, model_path)\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../models/RNN/my_RNN_model_S9_40\n",
      "RMSE: 0.5349453091621399\n",
      "[[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " ...\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "(2384, 1) (2384, 1)\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "saver.restore(sess, model_path)\n",
    "\n",
    "# Test step\n",
    "test_predict = sess.run(Y_pred, feed_dict={X: X_train})\n",
    "rmse_val = sess.run(rmse, feed_dict={\n",
    "                    targets: y_train, predictions: test_predict})\n",
    "print(\"RMSE: {}\".format(rmse_val))\n",
    "\n",
    "y_pred = sess.run(Y_pred,feed_dict={X: X_test})\n",
    "y_pred[y_pred<0.5] = 0\n",
    "y_pred[y_pred>=0.5] = 1\n",
    "print(y_pred)\n",
    "y_true = y_test\n",
    "print(y_pred.shape, y_true.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Score: 1.0\n",
      "Accuracy:  1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00      2384\n",
      "\n",
      "avg / total       1.00      1.00      1.00      2384\n",
      "\n",
      "[[2384]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "fig = plt.figure(figsize=(10,8))\n",
    "plt.plot(cost_history)\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.xlabel(\"Iterations\") \n",
    "plt.axis([0,len(cost_history),0,np.max(cost_history)])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "p,r,f,s = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "print(\"F-Score:\", round(f,3))\n",
    "print(\"Accuracy: \", accuracy_score(y_true, y_pred))\n",
    "\n",
    "print(classification_report(y_true, y_pred))\n",
    "print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../models/RNN/my_RNN_model_S9_40\n",
      "(442368,)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-9256aef6a54d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;31m#showFreqTime([[sample, filename1, SR]])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0mspectrogram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mspectrogram\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmean\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mstd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[0mdataX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspectrogram\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mean' is not defined"
     ]
    }
   ],
   "source": [
    "model_path_f = '../models/RNN/'\n",
    "filename = 'my_RNN_model_S9_40.meta'\n",
    "\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "loader = tf.train.import_meta_graph(model_path_f+filename)\n",
    "loader.restore(sess, tf.train.latest_checkpoint(model_path_f))\n",
    "\n",
    "SR = 22050\n",
    "####\n",
    "justone = True\n",
    "\n",
    "while(justone):\n",
    "    justone = False\n",
    "    #print(\"start to record the audio.\")\n",
    "    '''\n",
    "    frames = []\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "    #print(\"Recording finished.\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "\n",
    "    p.terminate()\n",
    "\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    '''\n",
    "    ####\n",
    "    filename1 = '../data/phantom/JUNE_01_PHANTOMS/wavs/22050/WSU_P2_LOADED_BACK_AND_FORTH.wav'\n",
    "    filename2 = '../data/phantom/JUNE_02_BACKGROUND/wavs/background/canopy_heavy_wind.wav'\n",
    "    \n",
    "    sample, sample_rate = librosa.load(filename1,SR)\n",
    "    print(sample.shape)\n",
    "    \n",
    "    \n",
    "    freqs, times, spectrogram = log_specgram(sample, sample_rate)    \n",
    "    #showFreqTime([[sample, filename1, SR]])  \n",
    "\n",
    "    spectrogram = (spectrogram - mean) / std\n",
    "    \n",
    "    dataX = spectrogram\n",
    "    #print(dataX.shape)\n",
    "    #print('delta shape:',dataX.shape)\n",
    "\n",
    "    X_hot_list= []\n",
    "    #print(dataX.shape[0] - seq_length+1)\n",
    "    for i in range(0, dataX.shape[0] - seq_length+1):\n",
    "        _x = dataX[i:i + seq_length]\n",
    "        X_hot_list.append(_x)\n",
    "    X_hot = np.array(X_hot_list[:])\n",
    "    #print(X_hot[0])\n",
    "    #print('\\n\\n\\n')\n",
    "    y_pred = sess.run(Y_pred,feed_dict={X: X_hot})\n",
    "    #y_pred[y_pred<0.5] = 0\n",
    "    #y_pred[y_pred>=0.5] = 1\n",
    "    print(y_pred[20:30] )\n",
    "    y_true = np.ones(shape=[y_pred.shape[0]])\n",
    "    y_pred[y_pred<0.5] = 0\n",
    "    y_pred[y_pred>=0.5] = 1\n",
    "    \n",
    "    p,r,f,s = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "    print(\"F-Score:\", round(f,3))\n",
    "    print(\"Accuracy: \", accuracy_score(y_true, y_pred))\n",
    "\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "    '''\n",
    "    if y_pred[0] == 1:\n",
    "        print('The sound is Drone')\n",
    "    else :\n",
    "        print('THe sound isn\\'t Drone')\n",
    "    '''\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
