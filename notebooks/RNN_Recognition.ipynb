{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "# Math\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "import pandas as pd\n",
    "import pyaudio\n",
    "import wave\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "seq_length = 9 #layer\n",
    "# train Parameters\n",
    "X_dim = 442 #n_dim #X_hot.shape[2]\n",
    "\n",
    "#seq_length = 7 #X_hot.shape[1]\n",
    "output_dim = 1 #n_classes #Y_hot.shape[1]\n",
    "\n",
    "hidden_dim = 2\n",
    "learning_rate = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, seq_length, X_dim], name = 'X')\n",
    "Y = tf.placeholder(tf.float32, [None, output_dim], name = 'Y')\n",
    "\n",
    "\n",
    "# build a LSTM network\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(\n",
    "    num_units=hidden_dim, state_is_tuple=True, activation=tf.tanh)\n",
    "outputs, _states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "\n",
    "Y_pred = tf.contrib.layers.fully_connected(\n",
    "    outputs[:, -1], output_dim, activation_fn=None)  # We use the last cell's output\n",
    "\n",
    "# cost/loss\n",
    "loss = tf.reduce_sum(tf.square(Y_pred - Y))  # sum of the squares\n",
    "#loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = Y_pred, labels = Y))\n",
    "# optimizer\n",
    "lr = tf.placeholder(tf.float32,shape=(), name='learning_rate')\n",
    "train = tf.train.AdamOptimizer(lr).minimize(loss) #AdamOptimizer\n",
    "\n",
    "# RMSE\n",
    "targets = tf.placeholder(tf.float32, [None, output_dim] , name = 'targets')\n",
    "predictions = tf.placeholder(tf.float32, [None, output_dim] , name = 'predictions')\n",
    "rmse = tf.sqrt(tf.reduce_mean(tf.square(targets - predictions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 개\t ../data/phantom/JUNE_01_PHANTOMS/wavs\\P1_stationary.wav\n",
      "21 개\t ../data/phantom/JUNE_02_BACKGROUND/wavs/background\\background_06_02_01.wav\n",
      "884736 44100 ../data/phantom/JUNE_01_PHANTOMS/wavs\\P1_stationary.wav\n",
      "884736 44100 ../data/phantom/JUNE_02_BACKGROUND/wavs/background\\background_06_02_01.wav\n",
      "(9732096,) (18579456,)\n"
     ]
    }
   ],
   "source": [
    "def log_specgram(audio, sample_rate, window_size=20,\n",
    "                 step_size=10, eps=1e-10):\n",
    "    nperseg = int(round(window_size * sample_rate / 1e3))\n",
    "    noverlap = int(round(step_size * sample_rate / 1e3))\n",
    "    freqs, times, spec = signal.spectrogram(audio,\n",
    "                                    fs=sample_rate,\n",
    "                                    window='hann',\n",
    "                                    nperseg=nperseg,\n",
    "                                    noverlap=noverlap,\n",
    "                                    detrend=False)\n",
    "    return freqs, times, np.log(spec.T.astype(np.float32) + eps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jh\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1711: UserWarning:\n",
      "\n",
      "An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../models/RNN/my_RNN_model_S27_100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../models/RNN/my_RNN_model_S27_100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(884736,)\n",
      "[[0.11929047]\n",
      " [0.10241126]\n",
      " [0.11078118]\n",
      " [0.20564024]\n",
      " [0.19021729]\n",
      " [0.45822024]\n",
      " [0.49594963]\n",
      " [0.32068068]\n",
      " [0.6434578 ]\n",
      " [0.16844624]]\n",
      "F-Score: 0.06\n",
      "Accuracy:  0.05958938407611417\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.00      0.00      0.00         0\n",
      "        1.0       1.00      0.06      0.11      1997\n",
      "\n",
      "avg / total       1.00      0.06      0.11      1997\n",
      "\n",
      "[[   0    0]\n",
      " [1878  119]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\jh\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning:\n",
      "\n",
      "Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_path_f = '../models/RNN/'\n",
    "filename = 'my_RNN_model_S27_100.meta'\n",
    "\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "loader = tf.train.import_meta_graph(model_path_f+filename)\n",
    "loader.restore(sess, tf.train.latest_checkpoint(model_path_f))\n",
    "\n",
    "SR = 44100\n",
    "sound_path = WAVE_OUTPUT_FILENAME\n",
    "####\n",
    "justone = True\n",
    "while(justone):\n",
    "    justone = False\n",
    "    p = pyaudio.PyAudio()\n",
    "    stream = p.open(format = FORMAT,channels = CHANNELS,rate = RATE,input = True,frames_per_buffer = CHUNK)\n",
    "\n",
    "    #print(\"start to record the audio.\")\n",
    "    '''\n",
    "    frames = []\n",
    "    for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "        data = stream.read(CHUNK)\n",
    "        frames.append(data)\n",
    "    #print(\"Recording finished.\")\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "\n",
    "    p.terminate()\n",
    "\n",
    "    wf = wave.open(WAVE_OUTPUT_FILENAME, 'wb')\n",
    "    wf.setnchannels(CHANNELS)\n",
    "    wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "    wf.setframerate(RATE)\n",
    "    wf.writeframes(b''.join(frames))\n",
    "    wf.close()\n",
    "    '''\n",
    "    ####\n",
    "    filename1 = '../data/phantom/JUNE_01_PHANTOMS/wavs/P1_stationary.wav'\n",
    "    filename2 = '../data/phantom/JUNE_02_BACKGROUND/wavs/background/background_06_02_01.wav'\n",
    "    \n",
    "    sample, sample_rate = librosa.load(filename1,SR)\n",
    "    print(sample.shape)\n",
    "    \n",
    "    \n",
    "    freqs, times, spectrogram = log_specgram(sample, sample_rate)    \n",
    "\n",
    "    mean = np.mean(spectrogram, axis=0)\n",
    "    std = np.std(spectrogram, axis=0)\n",
    "    spectrogram = (spectrogram - mean) / std\n",
    "    \n",
    "    dataX = spectrogram\n",
    "    #print(dataX.shape)\n",
    "    #print('delta shape:',dataX.shape)\n",
    "\n",
    "    X_hot_list= []\n",
    "    #print(dataX.shape[0] - seq_length+1)\n",
    "    for i in range(0, dataX.shape[0] - seq_length+1):\n",
    "        _x = dataX[i:i + seq_length]\n",
    "        X_hot_list.append(_x)\n",
    "    X_hot = np.array(X_hot_list[:])\n",
    "    #print(X_hot[0])\n",
    "    #print('\\n\\n\\n')\n",
    "    y_pred = sess.run(Y_pred,feed_dict={X: X_hot})\n",
    "    #y_pred[y_pred<0.5] = 0\n",
    "    #y_pred[y_pred>=0.5] = 1\n",
    "    print(y_pred[:10] )\n",
    "    y_true = np.ones(shape=[y_pred.shape[0]])\n",
    "    y_pred[y_pred<0.5] = 0\n",
    "    y_pred[y_pred>=0.5] = 1\n",
    "    \n",
    "    p,r,f,s = precision_recall_fscore_support(y_true, y_pred, average='micro')\n",
    "    print(\"F-Score:\", round(f,3))\n",
    "    print(\"Accuracy: \", accuracy_score(y_true, y_pred))\n",
    "\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(confusion_matrix(y_true, y_pred))\n",
    "\n",
    "    '''\n",
    "    if y_pred[0] == 1:\n",
    "        print('The sound is Drone')\n",
    "    else :\n",
    "        print('THe sound isn\\'t Drone')\n",
    "    '''\n",
    "\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
